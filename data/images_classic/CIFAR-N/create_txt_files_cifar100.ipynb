{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# import torchvision\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['clean_label', 'noisy_label', 'clean_coarse_label', 'noisy_coarse_label'])\n",
      "[19 63 10 11  1 86 90 28 23 31]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cifar10n_labels = torch.load(\"CIFAR-100_human.pt\")\n",
    "\n",
    "print(cifar10n_labels.keys())\n",
    "print(cifar10n_labels[\"noisy_label\"][:10])\n",
    "\n",
    "classname_dict = {\n",
    "    0: 'apple', 1: 'aquarium_fish', 2: 'baby', 3: 'bear', 4: 'beaver', 5: 'bed', 6: 'bee', 7: 'beetle', 8: 'bicycle', 9: 'bottle', 10: 'bowl', 11: 'boy', 12: 'bridge', 13: 'bus', 14: 'butterfly', 15: 'camel', 16: 'can', 17: 'castle', 18: 'caterpillar', 19: 'cattle', 20: 'chair', 21: 'chimpanzee', 22: 'clock', 23: 'cloud', 24: 'cockroach', 25: 'couch', 26: 'crab', 27: 'crocodile', 28: 'cup', 29: 'dinosaur', 30: 'dolphin', 31: 'elephant', 32: 'flatfish', 33: 'forest', 34: 'fox', 35: 'girl', 36: 'hamster', 37: 'house', 38: 'kangaroo', 39: 'keyboard', 40: 'lamp', 41: 'lawn_mower', 42: 'leopard', 43: 'lion', 44: 'lizard', 45: 'lobster', 46: 'man', 47: 'maple_tree', 48: 'motorcycle', 49: 'mountain', 50: 'mouse', 51: 'mushroom', 52: 'oak_tree', 53: 'orange', 54: 'orchid', 55: 'otter', 56: 'palm_tree', 57: 'pear', 58: 'pickup_truck', 59: 'pine_tree', 60: 'plain', 61: 'plate', 62: 'poppy', 63: 'porcupine', 64: 'possum', 65: 'rabbit', 66: 'raccoon', 67: 'ray', 68: 'road', 69: 'rocket', 70: 'rose', 71: 'sea', 72: 'seal', 73: 'shark', 74: 'shrew', 75: 'skunk', 76: 'skyscraper', 77: 'snail', 78: 'snake', 79: 'spider', 80: 'squirrel', 81: 'streetcar', 82: 'sunflower', 83: 'sweet_pepper', 84: 'table', 85: 'tank', 86: 'telephone', 87: 'television', 88: 'tiger', 89: 'tractor', 90: 'train', 91: 'trout', 92: 'tulip', 93: 'turtle', 94: 'wardrobe', 95: 'whale', 96: 'willow_tree', 97: 'wolf', 98: 'woman', 99: 'worm'}\n",
    "\n",
    "superclass_dict = {\n",
    "    0: 'aquatic animals',\n",
    "    1: 'fish',\n",
    "    2: 'flowers',\n",
    "    3: 'food containers',\n",
    "    4: 'fruit and vegetables',\n",
    "    5: 'household electrical devices',\n",
    "    6: 'household furniture',\n",
    "    7: 'insects',\n",
    "    8: 'large carnivores',\n",
    "    9: 'large man-made outdoor things',\n",
    "    10: 'large natural outdoor scenes',\n",
    "    11: 'large omnivores and herbivores',\n",
    "    12: 'medium-sized mammals',\n",
    "    13: 'non-insect invertebrates',\n",
    "    14: 'people',\n",
    "    15: 'reptiles',\n",
    "    16: 'small mammals',\n",
    "    17: 'trees',\n",
    "    18: 'vehicles 1',\n",
    "    19: 'vehicles 2'\n",
    "}\n",
    "\n",
    "def sparse2coarse(targets):\n",
    "    \"\"\"Convert Pytorch CIFAR100 sparse targets to coarse targets.\n",
    "\n",
    "    Usage:\n",
    "        trainset = torchvision.datasets.CIFAR100(path)\n",
    "        trainset.targets = sparse2coarse(trainset.targets)\n",
    "    \"\"\"\n",
    "    coarse_labels = np.array([ 4,  1, 14,  8,  0,  6,  7,  7, 18,  3,  \n",
    "                               3, 14,  9, 18,  7, 11,  3,  9,  7, 11,\n",
    "                               6, 11,  5, 10,  7,  6, 13, 15,  3, 15,  \n",
    "                               0, 11,  1, 10, 12, 14, 16,  9, 11,  5, \n",
    "                               5, 19,  8,  8, 15, 13, 14, 17, 18, 10, \n",
    "                               16, 4, 17,  4,  2,  0, 17,  4, 18, 17, \n",
    "                               10, 3,  2, 12, 12, 16, 12,  1,  9, 19,  \n",
    "                               2, 10,  0,  1, 16, 12,  9, 13, 15, 13, \n",
    "                              16, 19,  2,  4,  6, 19,  5,  5,  8, 19, \n",
    "                              18,  1,  2, 15,  6,  0, 17,  8, 14, 13])\n",
    "    return coarse_labels[targets]\n",
    "# reverse the dictionary\n",
    "#classname_dict = {v: k for k, v in classname_dict.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              label_orig  label_coarse\n",
      "filename                                              \n",
      "cifar100/test/apple/0040.png           0             4\n",
      "cifar100/test/apple/0074.png           0             4\n",
      "cifar100/test/apple/0089.png           0             4\n",
      "cifar100/test/apple/0080.png           0             4\n",
      "cifar100/test/apple/0049.png           0             4\n",
      "                              label_orig  label_coarse\n",
      "filename                                              \n",
      "cifar100/test/apple/0076.png           0             4\n",
      "cifar100/test/apple/0009.png           0             4\n",
      "cifar100/test/apple/0063.png           0             4\n",
      "cifar100/test/apple/0008.png           0             4\n",
      "cifar100/test/apple/0097.png           0             4\n"
     ]
    }
   ],
   "source": [
    "for split in [\"val\",\"test\"]:\n",
    "    train_df = pd.read_csv(f\"../../benchmark_imglist/cifar100/{split}_cifar100.txt\", sep=\" \", header=None)\n",
    "    train_df.columns = [\"filename\", \"label_orig\"]\n",
    "    train_df.set_index(\"filename\", inplace=True)\n",
    "    train_df[\"label_coarse\"] = sparse2coarse(train_df[\"label_orig\"])\n",
    "    print(train_df.head())\n",
    "    train_df.to_csv(f\"../../benchmark_imglist/cifar100/{split}_cifar100n_cleancoarse.txt\", sep=\" \", header=False, columns=[\"label_coarse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cattle': 500, 'dinosaur': 500, 'apple': 500, 'boy': 500, 'aquarium_fish': 500, 'telephone': 500, 'train': 500, 'cup': 500, 'cloud': 500, 'elephant': 500, 'keyboard': 500, 'willow_tree': 500, 'sunflower': 500, 'castle': 500, 'sea': 500, 'bicycle': 500, 'wolf': 500, 'squirrel': 500, 'shrew': 500, 'pine_tree': 500, 'rose': 500, 'television': 500, 'table': 500, 'possum': 500, 'oak_tree': 500, 'leopard': 500, 'maple_tree': 500, 'rabbit': 500, 'chimpanzee': 500, 'clock': 500, 'streetcar': 500, 'cockroach': 500, 'snake': 500, 'lobster': 500, 'mountain': 500, 'palm_tree': 500, 'skyscraper': 500, 'tractor': 500, 'shark': 500, 'butterfly': 500, 'bottle': 500, 'bee': 500, 'chair': 500, 'woman': 500, 'hamster': 500, 'otter': 500, 'seal': 500, 'lion': 500, 'mushroom': 500, 'girl': 500, 'sweet_pepper': 500, 'forest': 500, 'crocodile': 500, 'orange': 500, 'tulip': 500, 'mouse': 500, 'camel': 500, 'caterpillar': 500, 'man': 500, 'skunk': 500, 'kangaroo': 500, 'raccoon': 500, 'snail': 500, 'rocket': 500, 'whale': 500, 'worm': 500, 'turtle': 500, 'beaver': 500, 'plate': 500, 'wardrobe': 500, 'road': 500, 'fox': 500, 'flatfish': 500, 'tiger': 500, 'ray': 500, 'dolphin': 500, 'poppy': 500, 'porcupine': 500, 'lamp': 500, 'crab': 500, 'motorcycle': 500, 'spider': 500, 'tank': 500, 'orchid': 500, 'lizard': 500, 'beetle': 500, 'bridge': 500, 'baby': 500, 'lawn_mower': 500, 'house': 500, 'bus': 500, 'couch': 500, 'bowl': 500, 'pear': 500, 'bed': 500, 'plain': 500, 'trout': 500, 'bear': 500, 'pickup_truck': 500, 'can': 500}\n",
      "Found 50000 images in total\n",
      "Found 50000 images in train set\n",
      "                               label_orig\n",
      "filename                                 \n",
      "cifar100/train/apple/0001.png           0\n",
      "cifar100/train/apple/0002.png           0\n",
      "cifar100/train/apple/0003.png           0\n",
      "cifar100/train/apple/0004.png           0\n",
      "cifar100/train/apple/0005.png           0\n",
      "                                       label_clean_fine  label_noisy_fine\n",
      "filename                                                                 \n",
      "cifar100/train/cattle/0001.png                       19                19\n",
      "cifar100/train/dinosaur/0001.png                     29                63\n",
      "cifar100/train/apple/0001.png                         0                10\n",
      "cifar100/train/boy/0001.png                          11                11\n",
      "cifar100/train/aquarium_fish/0001.png                 1                 1\n",
      "                               label_orig  label_clean_fine  label_noisy_fine\n",
      "filename                                                                     \n",
      "cifar100/train/apple/0001.png           0                 0                10\n",
      "cifar100/train/apple/0002.png           0                 0                 0\n",
      "cifar100/train/apple/0003.png           0                 0                 0\n",
      "cifar100/train/apple/0004.png           0                 0                 0\n",
      "cifar100/train/apple/0005.png           0                 0                 0\n",
      "After merging, the number of rows in the train_df_noisy is 50000\n",
      "                               label_orig  label_noisy_fine\n",
      "filename                                                   \n",
      "cifar100/train/apple/0001.png           0                10\n",
      "cifar100/train/apple/0002.png           0                 0\n",
      "cifar100/train/apple/0003.png           0                 0\n",
      "cifar100/train/apple/0004.png           0                 0\n",
      "cifar100/train/apple/0005.png           0                 0\n"
     ]
    }
   ],
   "source": [
    "for split in [\"train\"]:\n",
    "    dataset_list = []\n",
    "    count_dict = {}\n",
    "\n",
    "    # combine train and test labels\n",
    "    #labels = trainset.targets\n",
    "\n",
    "    for i,_ in enumerate(cifar10n_labels[\"clean_label\"]):\n",
    "        label = cifar10n_labels[\"clean_label\"][i]\n",
    "        classname = classname_dict[label]\n",
    "        count_dict[classname] = count_dict.get(classname, 0) + 1\n",
    "\n",
    "        # if count_dict[classname] == 1:\n",
    "        #     # save the image\n",
    "        #     img = torchvision.transforms.ToTensor()(trainset.data[i])\n",
    "        #     torchvision.utils.save_image(img, f\"{classname}-{count_dict[classname]:04}.png\")\n",
    "        \n",
    "        if split in [\"val\",\"test\"]: source_folder = \"test\"\n",
    "        else: source_folder = \"train\"\n",
    "        filename = f\"cifar100/{source_folder}/{classname}/{count_dict[classname]:>04}.png\"\n",
    "        #print(cifar10n_labels)\n",
    "        dataset_list.append(\n",
    "            {\n",
    "                \"filename\": filename,\n",
    "                #\"label_orig\": label,\n",
    "                \"label_clean_fine\": cifar10n_labels[\"clean_label\"][i],\n",
    "                \"label_noisy_fine\": cifar10n_labels[\"noisy_label\"][i]\n",
    "            }\n",
    "        )\n",
    "\n",
    "    print(count_dict)\n",
    "\n",
    "    # create dataframe\n",
    "    df = pd.DataFrame(dataset_list)\n",
    "\n",
    "    print(f\"Found {len(df)} images in total\")\n",
    "\n",
    "    df.set_index(\"filename\", inplace=True)\n",
    "\n",
    "    # load txt file data/benchmark_imglist/cifar10/train_cifar10.txt\n",
    "    train_df = pd.read_csv(f\"../../benchmark_imglist/cifar100/{split}_cifar100.txt\", sep=\" \", header=None)\n",
    "\n",
    "    # rename columns to match\n",
    "    train_df.columns = [\"filename\", \"label_orig\"]\n",
    "\n",
    "    # update index of both dataframes\n",
    "    train_df.set_index(\"filename\", inplace=True)\n",
    "    \n",
    "    print(f\"Found {len(train_df)} images in {split} set\")\n",
    "\n",
    "    #sort both dataframes by index\n",
    "    #train_df.sort_index(inplace=True)\n",
    "    #df.sort_index(inplace=True)\n",
    "    print(train_df.head())\n",
    "    print(df.head())\n",
    "\n",
    "    # create new dataframe with updated labels but the order of the train_df\n",
    "    #train_df_noisy = pd.concat([train_df, df], axis=1, join=\"inner\")\n",
    "    train_df_noisy = train_df.merge(df, how=\"left\", left_index=True, right_index=True)\n",
    "    print(train_df_noisy.head())\n",
    "\n",
    "    # remove column 1\n",
    "    train_df_noisy.drop(columns=[\"label_clean_fine\"], inplace=True)\n",
    "\n",
    "    #print(train_df.head())\n",
    "    #print(train_df_noisy.head())\n",
    "    # remove rows from df_new that are not in df\n",
    "    train_df_noisy = train_df_noisy[train_df_noisy.index.isin(train_df.index)]\n",
    "\n",
    "    print(f\"After merging, the number of rows in the train_df_noisy is {len(train_df_noisy)}\")\n",
    "\n",
    "    print(train_df_noisy.head())\n",
    "\n",
    "    # save the new dataframes as txt files, selecting the label_worse column\n",
    "    train_df_noisy.to_csv(f\"../../benchmark_imglist/cifar100/{split}_cifar100n_noisyfine.txt\", sep=\" \", header=False, columns=[\"label_noisy_fine\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cattle': 500, 'dinosaur': 500, 'apple': 500, 'boy': 500, 'aquarium_fish': 500, 'telephone': 500, 'train': 500, 'cup': 500, 'cloud': 500, 'elephant': 500, 'keyboard': 500, 'willow_tree': 500, 'sunflower': 500, 'castle': 500, 'sea': 500, 'bicycle': 500, 'wolf': 500, 'squirrel': 500, 'shrew': 500, 'pine_tree': 500, 'rose': 500, 'television': 500, 'table': 500, 'possum': 500, 'oak_tree': 500, 'leopard': 500, 'maple_tree': 500, 'rabbit': 500, 'chimpanzee': 500, 'clock': 500, 'streetcar': 500, 'cockroach': 500, 'snake': 500, 'lobster': 500, 'mountain': 500, 'palm_tree': 500, 'skyscraper': 500, 'tractor': 500, 'shark': 500, 'butterfly': 500, 'bottle': 500, 'bee': 500, 'chair': 500, 'woman': 500, 'hamster': 500, 'otter': 500, 'seal': 500, 'lion': 500, 'mushroom': 500, 'girl': 500, 'sweet_pepper': 500, 'forest': 500, 'crocodile': 500, 'orange': 500, 'tulip': 500, 'mouse': 500, 'camel': 500, 'caterpillar': 500, 'man': 500, 'skunk': 500, 'kangaroo': 500, 'raccoon': 500, 'snail': 500, 'rocket': 500, 'whale': 500, 'worm': 500, 'turtle': 500, 'beaver': 500, 'plate': 500, 'wardrobe': 500, 'road': 500, 'fox': 500, 'flatfish': 500, 'tiger': 500, 'ray': 500, 'dolphin': 500, 'poppy': 500, 'porcupine': 500, 'lamp': 500, 'crab': 500, 'motorcycle': 500, 'spider': 500, 'tank': 500, 'orchid': 500, 'lizard': 500, 'beetle': 500, 'bridge': 500, 'baby': 500, 'lawn_mower': 500, 'house': 500, 'bus': 500, 'couch': 500, 'bowl': 500, 'pear': 500, 'bed': 500, 'plain': 500, 'trout': 500, 'bear': 500, 'pickup_truck': 500, 'can': 500}\n",
      "Found 50000 images in total\n",
      "Found 50000 images in train set\n",
      "                               label_orig\n",
      "filename                                 \n",
      "cifar100/train/apple/0001.png           0\n",
      "cifar100/train/apple/0002.png           0\n",
      "cifar100/train/apple/0003.png           0\n",
      "cifar100/train/apple/0004.png           0\n",
      "cifar100/train/apple/0005.png           0\n",
      "                                       label_clean_fine  label_noisy_fine  \\\n",
      "filename                                                                    \n",
      "cifar100/train/cattle/0001.png                       19                19   \n",
      "cifar100/train/dinosaur/0001.png                     29                63   \n",
      "cifar100/train/apple/0001.png                         0                10   \n",
      "cifar100/train/boy/0001.png                          11                11   \n",
      "cifar100/train/aquarium_fish/0001.png                 1                 1   \n",
      "\n",
      "                                       label_clean_coarse  label_noisy_coarse  \n",
      "filename                                                                       \n",
      "cifar100/train/cattle/0001.png                         11                  11  \n",
      "cifar100/train/dinosaur/0001.png                       15                  12  \n",
      "cifar100/train/apple/0001.png                           4                   3  \n",
      "cifar100/train/boy/0001.png                            14                  14  \n",
      "cifar100/train/aquarium_fish/0001.png                   1                   1  \n",
      "                               label_orig  label_clean_fine  label_noisy_fine  \\\n",
      "filename                                                                        \n",
      "cifar100/train/apple/0001.png           0                 0                10   \n",
      "cifar100/train/apple/0002.png           0                 0                 0   \n",
      "cifar100/train/apple/0003.png           0                 0                 0   \n",
      "cifar100/train/apple/0004.png           0                 0                 0   \n",
      "cifar100/train/apple/0005.png           0                 0                 0   \n",
      "\n",
      "                               label_clean_coarse  label_noisy_coarse  \n",
      "filename                                                               \n",
      "cifar100/train/apple/0001.png                   4                   3  \n",
      "cifar100/train/apple/0002.png                   4                   4  \n",
      "cifar100/train/apple/0003.png                   4                   4  \n",
      "cifar100/train/apple/0004.png                   4                   4  \n",
      "cifar100/train/apple/0005.png                   4                   4  \n",
      "After merging, the number of rows in the train_df_noisy is 50000\n",
      "                               label_orig  label_noisy_fine  \\\n",
      "filename                                                      \n",
      "cifar100/train/apple/0001.png           0                10   \n",
      "cifar100/train/apple/0002.png           0                 0   \n",
      "cifar100/train/apple/0003.png           0                 0   \n",
      "cifar100/train/apple/0004.png           0                 0   \n",
      "cifar100/train/apple/0005.png           0                 0   \n",
      "\n",
      "                               label_clean_coarse  label_noisy_coarse  \n",
      "filename                                                               \n",
      "cifar100/train/apple/0001.png                   4                   3  \n",
      "cifar100/train/apple/0002.png                   4                   4  \n",
      "cifar100/train/apple/0003.png                   4                   4  \n",
      "cifar100/train/apple/0004.png                   4                   4  \n",
      "cifar100/train/apple/0005.png                   4                   4  \n"
     ]
    }
   ],
   "source": [
    "for split in [\"train\"]:\n",
    "    dataset_list = []\n",
    "    count_dict = {}\n",
    "\n",
    "    # combine train and test labels\n",
    "    #labels = trainset.targets\n",
    "\n",
    "    for i,_ in enumerate(cifar10n_labels[\"clean_label\"]):\n",
    "        label = cifar10n_labels[\"clean_label\"][i]\n",
    "        classname = classname_dict[label]\n",
    "        count_dict[classname] = count_dict.get(classname, 0) + 1\n",
    "\n",
    "        # if count_dict[classname] == 1:\n",
    "        #     # save the image\n",
    "        #     img = torchvision.transforms.ToTensor()(trainset.data[i])\n",
    "        #     torchvision.utils.save_image(img, f\"{classname}-{count_dict[classname]:04}.png\")\n",
    "        \n",
    "        if split in [\"val\",\"test\"]: source_folder = \"test\"\n",
    "        else: source_folder = \"train\"\n",
    "        filename = f\"cifar100/{source_folder}/{classname}/{count_dict[classname]:>04}.png\"\n",
    "        #print(cifar10n_labels)\n",
    "        dataset_list.append(\n",
    "            {\n",
    "                \"filename\": filename,\n",
    "                #\"label_orig\": label,\n",
    "                \"label_clean_fine\": cifar10n_labels[\"clean_label\"][i],\n",
    "                \"label_noisy_fine\": cifar10n_labels[\"noisy_label\"][i],\n",
    "                \"label_clean_coarse\": cifar10n_labels[\"clean_coarse_label\"][i],\n",
    "                \"label_noisy_coarse\": cifar10n_labels[\"noisy_coarse_label\"][i],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    print(count_dict)\n",
    "\n",
    "    # create dataframe\n",
    "    df = pd.DataFrame(dataset_list)\n",
    "\n",
    "    print(f\"Found {len(df)} images in total\")\n",
    "\n",
    "    df.set_index(\"filename\", inplace=True)\n",
    "\n",
    "    # load txt file data/benchmark_imglist/cifar10/train_cifar10.txt\n",
    "    train_df = pd.read_csv(f\"../../benchmark_imglist/cifar100/{split}_cifar100.txt\", sep=\" \", header=None)\n",
    "\n",
    "    # rename columns to match\n",
    "    train_df.columns = [\"filename\", \"label_orig\"]\n",
    "\n",
    "    # update index of both dataframes\n",
    "    train_df.set_index(\"filename\", inplace=True)\n",
    "    \n",
    "    print(f\"Found {len(train_df)} images in {split} set\")\n",
    "\n",
    "    #sort both dataframes by index\n",
    "    #train_df.sort_index(inplace=True)\n",
    "    #df.sort_index(inplace=True)\n",
    "    print(train_df.head())\n",
    "    print(df.head())\n",
    "\n",
    "    # create new dataframe with updated labels but the order of the train_df\n",
    "    #train_df_noisy = pd.concat([train_df, df], axis=1, join=\"inner\")\n",
    "    train_df_noisy = train_df.merge(df, how=\"left\", left_index=True, right_index=True)\n",
    "    print(train_df_noisy.head())\n",
    "\n",
    "    # remove column 1\n",
    "    train_df_noisy.drop(columns=[\"label_clean_fine\"], inplace=True)\n",
    "\n",
    "    #print(train_df.head())\n",
    "    #print(train_df_noisy.head())\n",
    "    # remove rows from df_new that are not in df\n",
    "    train_df_noisy = train_df_noisy[train_df_noisy.index.isin(train_df.index)]\n",
    "\n",
    "    print(f\"After merging, the number of rows in the train_df_noisy is {len(train_df_noisy)}\")\n",
    "\n",
    "    print(train_df_noisy.head())\n",
    "\n",
    "    # save the new dataframes as txt files, selecting the label_worse column\n",
    "    train_df_noisy.to_csv(f\"../../benchmark_imglist/cifar100/{split}_cifar100n_noisycoarse.txt\", sep=\" \", header=False, columns=[\"label_noisy_coarse\"])\n",
    "    train_df_noisy.to_csv(f\"../../benchmark_imglist/cifar100/{split}_cifar100n_noisyfine.txt\", sep=\" \", header=False, columns=[\"label_noisy_fine\"])\n",
    "    train_df_noisy.to_csv(f\"../../benchmark_imglist/cifar100/{split}_cifar100n_cleancoarse.txt\", sep=\" \", header=False, columns=[\"label_clean_coarse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
