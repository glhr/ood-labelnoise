{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#import torchvision\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['clean_label', 'aggre_label', 'worse_label', 'random_label1', 'random_label2', 'random_label3'])\n",
      "[4 9 0 5 1 9 2 4 8 8]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cifar10n_labels = torch.load(\"CIFAR-10_human.pt\")\n",
    "\n",
    "print(cifar10n_labels.keys())\n",
    "print(cifar10n_labels[\"worse_label\"][:10])\n",
    "\n",
    "classname_dict = {\n",
    "    \"airplane\": 0,\n",
    "    \"automobile\": 1,\n",
    "    \"bird\": 2,\n",
    "    \"cat\": 3,\n",
    "    \"deer\": 4,\n",
    "    \"dog\": 5,\n",
    "    \"frog\": 6,\n",
    "    \"horse\": 7,\n",
    "    \"ship\": 8,\n",
    "    \"truck\": 9\n",
    "}\n",
    "# reverse the dictionary\n",
    "classname_dict = {v: k for k, v in classname_dict.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'filename': 'cifar10/train/frog/0001.png', 'label_worse': 4, 'label_clean': 6, 'label_agg': 6, 'label_random1': 6, 'label_random2': 4, 'label_random3': 6}, {'filename': 'cifar10/train/truck/0001.png', 'label_worse': 9, 'label_clean': 9, 'label_agg': 9, 'label_random1': 9, 'label_random2': 9, 'label_random3': 9}, {'filename': 'cifar10/train/truck/0002.png', 'label_worse': 0, 'label_clean': 9, 'label_agg': 9, 'label_random1': 9, 'label_random2': 9, 'label_random3': 0}, {'filename': 'cifar10/train/deer/0001.png', 'label_worse': 5, 'label_clean': 4, 'label_agg': 4, 'label_random1': 4, 'label_random2': 5, 'label_random3': 4}, {'filename': 'cifar10/train/automobile/0001.png', 'label_worse': 1, 'label_clean': 1, 'label_agg': 1, 'label_random1': 1, 'label_random2': 1, 'label_random3': 1}, {'filename': 'cifar10/train/automobile/0002.png', 'label_worse': 9, 'label_clean': 1, 'label_agg': 1, 'label_random1': 1, 'label_random2': 1, 'label_random3': 9}, {'filename': 'cifar10/train/bird/0001.png', 'label_worse': 2, 'label_clean': 2, 'label_agg': 2, 'label_random1': 2, 'label_random2': 2, 'label_random3': 2}, {'filename': 'cifar10/train/horse/0001.png', 'label_worse': 4, 'label_clean': 7, 'label_agg': 7, 'label_random1': 7, 'label_random2': 7, 'label_random3': 4}, {'filename': 'cifar10/train/ship/0001.png', 'label_worse': 8, 'label_clean': 8, 'label_agg': 8, 'label_random1': 8, 'label_random2': 8, 'label_random3': 8}, {'filename': 'cifar10/train/cat/0001.png', 'label_worse': 8, 'label_clean': 3, 'label_agg': 0, 'label_random1': 3, 'label_random2': 0, 'label_random3': 8}]\n",
      "Found 50000 images in total\n",
      "Found 50000 images in train set\n",
      "                            label_orig\n",
      "filename                              \n",
      "cifar10/train/cat/3975.png           3\n",
      "cifar10/train/cat/1804.png           3\n",
      "cifar10/train/cat/4968.png           3\n",
      "cifar10/train/cat/1810.png           3\n",
      "cifar10/train/cat/3961.png           3\n",
      "                                   label_worse  label_clean  label_agg  \\\n",
      "filename                                                                 \n",
      "cifar10/train/frog/0001.png                  4            6          6   \n",
      "cifar10/train/truck/0001.png                 9            9          9   \n",
      "cifar10/train/truck/0002.png                 0            9          9   \n",
      "cifar10/train/deer/0001.png                  5            4          4   \n",
      "cifar10/train/automobile/0001.png            1            1          1   \n",
      "\n",
      "                                   label_random1  label_random2  label_random3  \n",
      "filename                                                                        \n",
      "cifar10/train/frog/0001.png                    6              4              6  \n",
      "cifar10/train/truck/0001.png                   9              9              9  \n",
      "cifar10/train/truck/0002.png                   9              9              0  \n",
      "cifar10/train/deer/0001.png                    4              5              4  \n",
      "cifar10/train/automobile/0001.png              1              1              1  \n",
      "                            label_orig  label_worse  label_clean  label_agg  \\\n",
      "filename                                                                      \n",
      "cifar10/train/cat/3975.png           3            3            3          3   \n",
      "cifar10/train/cat/1804.png           3            7            3          3   \n",
      "cifar10/train/cat/4968.png           3            3            3          3   \n",
      "cifar10/train/cat/1810.png           3            3            3          3   \n",
      "cifar10/train/cat/3961.png           3            0            3          3   \n",
      "\n",
      "                            label_random1  label_random2  label_random3  \n",
      "filename                                                                 \n",
      "cifar10/train/cat/3975.png              3              3              3  \n",
      "cifar10/train/cat/1804.png              3              3              7  \n",
      "cifar10/train/cat/4968.png              3              3              3  \n",
      "cifar10/train/cat/1810.png              3              3              3  \n",
      "cifar10/train/cat/3961.png              0              3              3  \n",
      "After merging, the number of rows in the train_df_noisy is 50000\n"
     ]
    }
   ],
   "source": [
    "for split in [\"train\"]:\n",
    "    dataset_list = []\n",
    "    count_dict = {}\n",
    "\n",
    "    # combine train and test labels\n",
    "    #labels = trainset.targets\n",
    "\n",
    "    for i,_ in enumerate(cifar10n_labels[\"clean_label\"]):\n",
    "        label = cifar10n_labels[\"clean_label\"][i]\n",
    "        classname = classname_dict[label]\n",
    "        count_dict[classname] = count_dict.get(classname, 0) + 1\n",
    "\n",
    "        # if count_dict[classname] == 1:\n",
    "        #     # save the image\n",
    "        #     img = torchvision.transforms.ToTensor()(trainset.data[i])\n",
    "        #     torchvision.utils.save_image(img, f\"{classname}-{count_dict[classname]:04}.png\")\n",
    "        \n",
    "        if split in [\"val\",\"test\"]: source_folder = \"test\"\n",
    "        else: source_folder = \"train\"\n",
    "        filename = f\"cifar10/{source_folder}/{classname}/{count_dict[classname]:>04}.png\"\n",
    "        dataset_list.append(\n",
    "            {\n",
    "                \"filename\": filename,\n",
    "                #\"label_orig\": label,\n",
    "                \"label_worse\": cifar10n_labels[\"worse_label\"][i],\n",
    "                \"label_clean\": cifar10n_labels[\"clean_label\"][i],\n",
    "                \"label_agg\": cifar10n_labels[\"aggre_label\"][i],\n",
    "                \"label_random1\": cifar10n_labels[\"random_label1\"][i],\n",
    "                \"label_random2\": cifar10n_labels[\"random_label2\"][i],\n",
    "                \"label_random3\": cifar10n_labels[\"random_label3\"][i],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    print(dataset_list[:10])\n",
    "\n",
    "    # create dataframe\n",
    "    df = pd.DataFrame(dataset_list)\n",
    "\n",
    "    print(f\"Found {len(df)} images in total\")\n",
    "\n",
    "    df.set_index(\"filename\", inplace=True)\n",
    "\n",
    "    # load txt file data/benchmark_imglist/cifar10/train_cifar10.txt\n",
    "    train_df = pd.read_csv(f\"../../benchmark_imglist/cifar10/{split}_cifar10.txt\", sep=\" \", header=None)\n",
    "\n",
    "    # rename columns to match\n",
    "    train_df.columns = [\"filename\", \"label_orig\"]\n",
    "\n",
    "    # update index of both dataframes\n",
    "    train_df.set_index(\"filename\", inplace=True)\n",
    "    \n",
    "    print(f\"Found {len(train_df)} images in {split} set\")\n",
    "\n",
    "    #sort both dataframes by index\n",
    "    #train_df.sort_index(inplace=True)\n",
    "    #df.sort_index(inplace=True)\n",
    "    print(train_df.head())\n",
    "    print(df.head())\n",
    "\n",
    "    # create new dataframe with updated labels but the order of the train_df\n",
    "    #train_df_noisy = pd.concat([train_df, df], axis=1, join=\"inner\")\n",
    "    train_df_noisy = train_df.merge(df, how=\"left\", left_index=True, right_index=True)\n",
    "    print(train_df_noisy.head())\n",
    "\n",
    "    # remove column 1\n",
    "    train_df_noisy.drop(columns=[\"label_clean\"], inplace=True)\n",
    "\n",
    "    #print(train_df.head())\n",
    "    #print(train_df_noisy.head())\n",
    "    # remove rows from df_new that are not in df\n",
    "    train_df_noisy = train_df_noisy[train_df_noisy.index.isin(train_df.index)]\n",
    "\n",
    "    print(f\"After merging, the number of rows in the train_df_noisy is {len(train_df_noisy)}\")\n",
    "\n",
    "    # save the new dataframes as txt files, selecting the label_worse column\n",
    "    train_df_noisy.to_csv(f\"../../benchmark_imglist/cifar10/{split}_cifar10n_worse.txt\", sep=\" \", header=False, columns=[\"label_worse\"])\n",
    "    train_df_noisy.to_csv(f\"../../benchmark_imglist/cifar10/{split}_cifar10n_agg.txt\", sep=\" \", header=False, columns=[\"label_agg\"])\n",
    "    train_df_noisy.to_csv(f\"../../benchmark_imglist/cifar10/{split}_cifar10n_random1.txt\", sep=\" \", header=False, columns=[\"label_random1\"])\n",
    "    train_df_noisy.to_csv(f\"../../benchmark_imglist/cifar10/{split}_cifar10n_random2.txt\", sep=\" \", header=False, columns=[\"label_random2\"])\n",
    "    train_df_noisy.to_csv(f\"../../benchmark_imglist/cifar10/{split}_cifar10n_random3.txt\", sep=\" \", header=False, columns=[\"label_random3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
