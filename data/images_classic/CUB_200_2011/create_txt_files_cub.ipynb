{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ded392f-c09f-4a71-bb42-0c8c4c5ed43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# load pkl file\n",
    "class_info = np.load(\"cub_osr_splits.pkl\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5489aa0b-3090-4486-83b3-050b511be299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 train classes and 100\n"
     ]
    }
   ],
   "source": [
    "train_classes = class_info['known_classes']\n",
    "train_classes_new_index = dict()\n",
    "for cls_orig, cls_new in zip(np.unique(train_classes),range(len(np.unique(train_classes)))):\n",
    "    train_classes_new_index[cls_orig] = cls_new\n",
    "\n",
    "open_set_classes = class_info['unknown_classes']\n",
    "open_set_classes_dict = {\n",
    "    \"all\": open_set_classes['Hard'] + open_set_classes['Medium'] + open_set_classes['Easy'],\n",
    "    \"easy\": open_set_classes['Easy'],\n",
    "    \"medium\": open_set_classes['Medium'],\n",
    "    \"hard\": open_set_classes['Hard']\n",
    "}\n",
    "print(f\"{len(train_classes)} train classes and {len(open_set_classes_dict['all'])} unseen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "234288f4-f17b-46d1-891f-cb212bd2b497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   img_id                                           filepath  target  \\\n",
      "0       1  001.Black_footed_Albatross/Black_Footed_Albatr...       1   \n",
      "1       2  001.Black_footed_Albatross/Black_Footed_Albatr...       1   \n",
      "2       3  001.Black_footed_Albatross/Black_Footed_Albatr...       1   \n",
      "3       4  001.Black_footed_Albatross/Black_Footed_Albatr...       1   \n",
      "4       5  001.Black_footed_Albatross/Black_Footed_Albatr...       1   \n",
      "\n",
      "   is_training_img  \n",
      "0                0  \n",
      "1                1  \n",
      "2                0  \n",
      "3                1  \n",
      "4                1  \n",
      "                                          image_path  label\n",
      "0  CUB_200_2011/CUB_200_2011/images/001.Black_foo...      0\n",
      "1  CUB_200_2011/CUB_200_2011/images/001.Black_foo...      0\n",
      "2  CUB_200_2011/CUB_200_2011/images/001.Black_foo...      0\n",
      "3  CUB_200_2011/CUB_200_2011/images/001.Black_foo...      0\n",
      "4  CUB_200_2011/CUB_200_2011/images/001.Black_foo...      0\n",
      "100 unique classes in train\n",
      "                                          image_path  label\n",
      "0  CUB_200_2011/CUB_200_2011/images/001.Black_foo...      0\n",
      "1  CUB_200_2011/CUB_200_2011/images/001.Black_foo...      0\n",
      "2  CUB_200_2011/CUB_200_2011/images/001.Black_foo...      0\n",
      "3  CUB_200_2011/CUB_200_2011/images/001.Black_foo...      0\n",
      "4  CUB_200_2011/CUB_200_2011/images/001.Black_foo...      0\n",
      "100 unique classes in val\n",
      "                                          image_path  label\n",
      "0  CUB_200_2011/CUB_200_2011/images/001.Black_foo...      0\n",
      "1  CUB_200_2011/CUB_200_2011/images/001.Black_foo...      0\n",
      "2  CUB_200_2011/CUB_200_2011/images/001.Black_foo...      0\n",
      "3  CUB_200_2011/CUB_200_2011/images/001.Black_foo...      0\n",
      "4  CUB_200_2011/CUB_200_2011/images/001.Black_foo...      0\n",
      "100 unique classes in test\n",
      "                                          image_path  label\n",
      "0  CUB_200_2011/CUB_200_2011/images/002.Laysan_Al...     -1\n",
      "1  CUB_200_2011/CUB_200_2011/images/002.Laysan_Al...     -1\n",
      "2  CUB_200_2011/CUB_200_2011/images/002.Laysan_Al...     -1\n",
      "3  CUB_200_2011/CUB_200_2011/images/002.Laysan_Al...     -1\n",
      "4  CUB_200_2011/CUB_200_2011/images/002.Laysan_Al...     -1\n",
      "1 unique classes in ood_easy\n",
      "                                          image_path  label\n",
      "0  CUB_200_2011/CUB_200_2011/images/003.Sooty_Alb...     -1\n",
      "1  CUB_200_2011/CUB_200_2011/images/003.Sooty_Alb...     -1\n",
      "2  CUB_200_2011/CUB_200_2011/images/003.Sooty_Alb...     -1\n",
      "3  CUB_200_2011/CUB_200_2011/images/003.Sooty_Alb...     -1\n",
      "4  CUB_200_2011/CUB_200_2011/images/003.Sooty_Alb...     -1\n",
      "1 unique classes in ood_medium\n",
      "                                          image_path  label\n",
      "0  CUB_200_2011/CUB_200_2011/images/004.Groove_bi...     -1\n",
      "1  CUB_200_2011/CUB_200_2011/images/004.Groove_bi...     -1\n",
      "2  CUB_200_2011/CUB_200_2011/images/004.Groove_bi...     -1\n",
      "3  CUB_200_2011/CUB_200_2011/images/004.Groove_bi...     -1\n",
      "4  CUB_200_2011/CUB_200_2011/images/004.Groove_bi...     -1\n",
      "1 unique classes in ood_hard\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "\n",
    "def find_classes(classes_file):\n",
    "\n",
    "    # read classes file, separating out image IDs and class names\n",
    "    image_ids = []\n",
    "    targets = []\n",
    "    f = open(classes_file, 'r')\n",
    "    for line in f:\n",
    "        split_line = line.split(' ')\n",
    "        image_ids.append(split_line[0])\n",
    "        targets.append(' '.join(split_line[1:]))\n",
    "    f.close()\n",
    "\n",
    "    # index class names\n",
    "    classes = np.unique(targets)\n",
    "    class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "    targets = [class_to_idx[c] for c in targets]\n",
    "\n",
    "    return (image_ids, targets, classes, class_to_idx)\n",
    "\n",
    "def subsample_dataset(dataset, idxs):\n",
    "    imgs,targets = dataset\n",
    "\n",
    "    imgs_sub = [p for i, (p, t) in enumerate(zip(imgs,targets)) if i in idxs]\n",
    "    targets_sub = [t for i, (p, t) in enumerate(zip(imgs,targets)) if i in idxs]\n",
    "\n",
    "    return (imgs_sub, targets_sub)\n",
    "\n",
    "def get_train_val_split(image_ids,targets, val_split=0.2):\n",
    "\n",
    "    val_dataset = (image_ids,targets)\n",
    "    train_dataset = (image_ids,targets)\n",
    "\n",
    "    train_classes = np.unique(targets)\n",
    "\n",
    "    # Get train/test indices\n",
    "    train_idxs = []\n",
    "    val_idxs = []\n",
    "    for cls in train_classes:\n",
    "\n",
    "        cls_idxs = np.where(targets == cls)[0]\n",
    "        #print(f\"{cls} has {len(cls_idxs)} examples\")\n",
    "\n",
    "        v_ = np.random.choice(cls_idxs, replace=False, size=((int(val_split * len(cls_idxs))),))\n",
    "        t_ = [x for x in cls_idxs if x not in v_]\n",
    "        #print(f\"{len(t_)} going in train\")\n",
    "\n",
    "        train_idxs.extend(t_)\n",
    "        val_idxs.extend(v_)\n",
    "\n",
    "    # Get training/validation datasets based on selected idxs\n",
    "    train_dataset = subsample_dataset(train_dataset, train_idxs)\n",
    "    val_dataset = subsample_dataset(val_dataset, val_idxs)\n",
    "\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "class_type='variant'\n",
    "split='train'\n",
    "\n",
    "# classes_file = os.path.join('data', 'images_%s_%s.txt' % (class_type, \"trainval\"))\n",
    "# (image_ids, targets, classes, class_to_idx) = find_classes(classes_file)\n",
    "\n",
    "\n",
    "images = pd.read_csv(os.path.join('CUB_200_2011', 'images.txt'), sep=' ',\n",
    "                     names=['img_id', 'filepath'])\n",
    "image_class_labels = pd.read_csv(os.path.join('CUB_200_2011', 'image_class_labels.txt'),\n",
    "                                 sep=' ', names=['img_id', 'target'])\n",
    "train_test_split = pd.read_csv(os.path.join('CUB_200_2011', 'train_test_split.txt'),\n",
    "                               sep=' ', names=['img_id', 'is_training_img'])\n",
    "\n",
    "data = images.merge(image_class_labels, on='img_id')\n",
    "data = data.merge(train_test_split, on='img_id')\n",
    "print(data.head())\n",
    "\n",
    "data_training = data[data[\"is_training_img\"] == 1]\n",
    "data_test = data[data[\"is_training_img\"] == 0]\n",
    "\n",
    "datasets = dict()\n",
    "datasets[\"train\"], datasets[\"val\"] = get_train_val_split(data_training[\"img_id\"], data_training[\"target\"])\n",
    "\n",
    "\n",
    "for split in [\"train\",\"val\",\"test\",\"ood_easy\",\"ood_medium\",\"ood_hard\"]:\n",
    "    split_fgvc = \"test\" if \"ood\" in split else split\n",
    "\n",
    "    if \"ood\" in split:\n",
    "        difficulty = split.split(\"_\")[-1]\n",
    "\n",
    "    if split_fgvc == \"test\":\n",
    "        df_split = data_test\n",
    "    elif split_fgvc in [\"train\",\"val\"]:\n",
    "        image_ids, targets = datasets[split_fgvc]\n",
    "        df_split = data_training[data_training[\"img_id\"].isin(image_ids)]\n",
    "    \n",
    "    res_list = []\n",
    "    \n",
    "    for _,row in df_split.iterrows():\n",
    "        #print(image_id, cls)\n",
    "        idx = row[\"target\"]-1\n",
    "        if split in [\"train\",\"val\",\"test\"] and idx in open_set_classes_dict[\"all\"]:\n",
    "            continue\n",
    "        elif \"ood\" in split and idx not in open_set_classes_dict[difficulty]:\n",
    "            continue\n",
    "        res_list.append({\n",
    "            'image_path': f\"CUB_200_2011/CUB_200_2011/images/{row['filepath']}\",\n",
    "            'label': train_classes_new_index[idx] if split in [\"train\",\"val\",\"test\"] else -1\n",
    "        })\n",
    "\n",
    "    suffix = \"clean\" if split in [\"train\",\"val\",\"test\"] else difficulty\n",
    "    \n",
    "    df = pd.DataFrame(res_list)\n",
    "    print(df.head())\n",
    "    print(f\"{len(df['label'].unique())} unique classes in {split}\")\n",
    "    assert len(df['image_path'].unique()) == len(df)\n",
    "    df.to_csv(f\"../../benchmark_imglist/fgvc-cub/{split.split('_')[0]}_fgvc-cub_{suffix}.txt\", sep=\" \", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3effea-a0c7-4b92-bab6-2d158689478f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9072d4bf-0f4e-483b-a018-211b229fedff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openood",
   "language": "python",
   "name": "openood"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
