{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_folder = \"./\"\n",
    "output_folder = \"../../benchmark_imglist/clothing1M\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create OpenOOD txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      label_noisy\n",
      "filename                                         \n",
      "images/2/46/50748838,3981129246.jpg             5\n",
      "images/2/56/860908654,4267574256.jpg           13\n",
      "images/9/38/436489045,3143453938.jpg            7\n",
      "images/0/67/486092382,2324083067.jpg            5\n",
      "images/4/55/4029117294,35432455.jpg            12\n",
      "                                       label_clean\n",
      "filename                                          \n",
      "images/7/88/339645240,2782721788.jpg             9\n",
      "images/3/32/3772565911,269049332.jpg             4\n",
      "images/5/05/3839087683,82531505.jpg              8\n",
      "images/7/80/4164884897,484083780.jpg             9\n",
      "images/8/34/1686078362,3758137834.jpg            9\n",
      "1037497\n",
      "72409\n",
      "                                       label_clean  label_noisy\n",
      "filename                                                       \n",
      "images/8/34/1686078362,3758137834.jpg            9            2\n",
      "images/2/36/1917154406,80090236.jpg              1            0\n",
      "images/0/57/2543139285,3171306057.jpg            6            6\n",
      "images/0/64/830178742,2470126064.jpg            11           11\n",
      "images/3/38/186495116,1683095338.jpg             6            6\n",
      "res: 37497\n"
     ]
    }
   ],
   "source": [
    "# load annotations for noisy labels\n",
    "df_noisy = pd.read_csv(f\"{dataset_folder}/annotations/noisy_label_kv.txt\", sep=\" \", header=None)\n",
    "df_noisy.columns = [\"filename\", \"label_noisy\"]\n",
    "df_noisy.set_index(\"filename\", inplace=True)\n",
    "print(df_noisy.head())\n",
    "\n",
    "# load annotations for clean labels\n",
    "df_clean = pd.read_csv(f\"{dataset_folder}/annotations/clean_label_kv.txt\", sep=\" \", header=None)\n",
    "df_clean.columns = [\"filename\", \"label_clean\"]\n",
    "df_clean.set_index(\"filename\", inplace=True)\n",
    "print(df_clean.head())\n",
    "\n",
    "print(len(df_noisy))\n",
    "print(len(df_clean))\n",
    "\n",
    "df_inner = pd.merge(df_clean, df_noisy, how=\"inner\", left_index=True, right_index=True)\n",
    "print(df_inner.head())\n",
    "df_inner = df_inner.dropna()\n",
    "\n",
    "print(f\"res: {len(df_inner)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Clean train --\n",
      "                                       label_clean  label_noisy\n",
      "filename                                                       \n",
      "images/0/00/1801019306,1542533000.jpg           13           13\n",
      "images/0/00/1850927850,668152000.jpg             3            1\n",
      "images/0/00/2026196786,3947897000.jpg            0            5\n",
      "images/0/00/2271882818,3909842000.jpg            7            7\n",
      "images/0/00/2327570466,3027662000.jpg            3            3\n",
      "-- Clean train --\n",
      "                                       label_clean  label_noisy\n",
      "filename                                                       \n",
      "images/0/00/1801019306,1542533000.jpg           13           13\n",
      "images/0/00/1850927850,668152000.jpg             3            1\n",
      "images/0/00/2026196786,3947897000.jpg            0            5\n",
      "images/0/00/2271882818,3909842000.jpg            7            7\n",
      "images/0/00/2327570466,3027662000.jpg            3            3\n",
      "-- Clean val --\n",
      "                                       label_clean  label_noisy\n",
      "filename                                                       \n",
      "images/0/00/1429296456,2096860000.jpg            7            6\n",
      "images/0/00/1778345552,1560703000.jpg           10           10\n",
      "images/0/00/2128192972,2221430000.jpg           10           10\n",
      "images/0/00/2301947609,2201797000.jpg            8            8\n",
      "images/0/00/2472908908,2814425000.jpg           13            0\n",
      "-- Clean test --\n",
      "                                       label_clean  label_noisy\n",
      "filename                                                       \n",
      "images/0/00/1278541879,867148000.jpg            13           13\n",
      "images/0/00/1298176222,2755628000.jpg           11           11\n",
      "images/0/00/1992782016,1485508000.jpg           11            1\n",
      "images/0/00/2281045900,1423836000.jpg            6            8\n",
      "images/0/00/2534502585,3213368000.jpg            8           12\n",
      "train clean: 24637\n",
      "train noisy: 24637\n",
      "../../benchmark_imglist/clothing1M/train_clothing1M_noisy.txt\n",
      "val clean: 7465\n",
      "[Errno 2] No such file or directory: '../../benchmark_imglist/clothing1M/val_clothing1M_noisy.txt'\n",
      "test clean: 5395\n",
      "[Errno 2] No such file or directory: '../../benchmark_imglist/clothing1M/test_clothing1M_noisy.txt'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for select in [\"noisy\",\"clean\"]:\n",
    "    # load train key file\n",
    "    splits = [\"train\", \"val\", \"test\"] if select == \"clean\" else [\"train\"]\n",
    "    for split in splits:\n",
    "        train_df = pd.read_csv(f\"{dataset_folder}/annotations/clean_{split}_key_list.txt\", sep=\" \", header=None)\n",
    "        train_df.columns = [\"filename\"]\n",
    "        train_df.set_index(\"filename\", inplace=True)\n",
    "    \n",
    "        print(f\"-- Clean {split} --\")\n",
    "        \n",
    "        # merge the two dataframes\n",
    "        train_df = train_df.merge(df_inner, how=\"inner\", left_index=True, right_index=True)\n",
    "        print(train_df.head())\n",
    "    \n",
    "        # append \"clothing1M\" to the filename\n",
    "        train_df.index = train_df.index.map(lambda x: f\"clothing1M/{x}\")\n",
    "        train_df\n",
    "    \n",
    "        # save the new dataframes as txt files\n",
    "        train_df.to_csv(f\"{output_folder}/{split}_clothing1M_{select}.txt\", sep=\" \", header=False, columns=[f\"label_{select}\"])\n",
    "\n",
    "\n",
    "# load the created txt files and check their length\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    train_df = pd.read_csv(f\"{output_folder}/{split}_clothing1M_clean.txt\", sep=\" \", header=None)\n",
    "    print(f\"{split} clean: {len(train_df)}\")#\n",
    "    try:\n",
    "        train_df = pd.read_csv(f\"{output_folder}/{split}_clothing1M_noisy.txt\", sep=\" \", header=None)\n",
    "        print(f\"{split} noisy: {len(train_df)}\")\n",
    "        print(f\"{output_folder}/{split}_clothing1M_noisy.txt\")\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
