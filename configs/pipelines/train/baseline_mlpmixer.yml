# based on https://github.com/kentaroy47/vision-transformers-cifar10/blob/main/train_cifar10.py

exp_name: "'@{dataset.name}'_'@{network.name}'_'@{trainer.name}'_e'@{optimizer.num_epochs}'_lr'@{optimizer.lr}'_'@{mark}'/s'@{seed}'"
output_dir: ./results/
save_output: True
merge_option: default
mark: default
seed: 0

num_gpus: 1
num_workers: 8
num_machines: 1
machine_rank: 0

preprocessor:
  name: base

network:
  pretrained: False

pipeline:
  name: train

trainer:
  name: base_mlpmixer

evaluator:
  name: base

optimizer:
  name: adam
  num_epochs: 500
  lr: 0.001 # 1e-3

scheduler:
  name: CosineAnnealingLR
  n_epochs: 500

recorder:
  name: base
  save_all_models: False
